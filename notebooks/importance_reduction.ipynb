{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "## imports for the program\n",
    "import os\n",
    "import io\n",
    "import csv\n",
    "import zlib\n",
    "import copy\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "import base64\n",
    "import joblib\n",
    "import hashlib\n",
    "import platform\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "from xgboost import plot_importance\n",
    "from scipy.optimize import fmin_powell\n",
    "\n",
    "# plot information in 3 dimensions\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "import plotly.graph_objects as go\n",
    "import kaleido\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import AgglomerativeClustering, DBSCAN, MeanShift, KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score, confusion_matrix, accuracy_score, mean_absolute_error\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# the pytorch module\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "# torch neural network items\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "\n",
    "# lime model evaluation\n",
    "from lime import lime_tabular\n",
    "\n",
    "# for encrypting the model and hashing it\n",
    "from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC\n",
    "from cryptography.hazmat.primitives import hashes\n",
    "from cryptography.hazmat.primitives.kdf.scrypt import Scrypt\n",
    "from cryptography.hazmat.backends import default_backend\n",
    "from cryptography.hazmat.primitives import serialization\n",
    "from cryptography.hazmat.primitives.asymmetric import rsa\n",
    "from cryptography.hazmat.primitives.asymmetric import padding\n",
    "from cryptography.fernet import Fernet, MultiFernet\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# code for xgboost found at https://www.kaggle.com/code/zeroblue/xgboost-with-optimized-offsets\n",
    "\n",
    "# defining the device for cuda\n",
    "if platform.system() == 'Darwin' and torch.backends.mps.is_available():\n",
    "\t\n",
    "\t# check if mps is available on mac\n",
    "\tdevice = torch.device('mps')  \n",
    "\n",
    "elif torch.cuda.is_available():\n",
    "\t\n",
    "\t# check if cuda is available\n",
    "    device = torch.device('cuda')  \n",
    "\n",
    "else:\n",
    "\t\n",
    "\t# fallback to cpu if cuda is not available\n",
    "\tdevice = torch.device('cpu')  \n",
    "\n",
    "# output the selected device\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global directory path\n",
    "HOME_DIR = os.path.expanduser('~')\n",
    "\n",
    "# the sub directory from the home direcotry\n",
    "SUB_DIR = \"Desktop/Classes/CPSC 471/Final Project/\"\n",
    "\n",
    "# directory that we should write info to\n",
    "OUT_DIR = \"models/node_importance_delta\"\n",
    "\n",
    "# where we are writing files to\n",
    "WRITE_DIR = os.path.join(\n",
    "\tHOME_DIR,\n",
    "\tSUB_DIR,\n",
    "\tOUT_DIR\n",
    ")\n",
    "\n",
    "BASELINE_SAVE_FILE_NAME = \"manipulate_nn.pth\"\n",
    "\n",
    "# check if we are running pca or normal\n",
    "TRAIN_PCA = True\n",
    "\n",
    "# get the batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# the number of times that we are going to run the importance-reduction to get \n",
    "# the average time for the operation\n",
    "RUN_TIMES = 5\n",
    "\n",
    "MAX_INDICIES_LEN_PLOTTING = 500\n",
    "\n",
    "# getting the colors for the plots \n",
    "PLOT_COLOR_1 = \"darkorange\"\n",
    "PLOT_COLOR_2 = \"dodgerblue\"\n",
    "\n",
    "# whether we should save the images\n",
    "SHOULD_SAVE_OUTPUT = True\n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the data using pandas\n",
      "Eliminate missing values\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "print(\"Load the data using pandas\")\n",
    "train = pd.read_csv(\"../final_471_datasets/train.csv\")\n",
    "test = pd.read_csv(\"../final_471_datasets/test.csv\")\n",
    "\n",
    "# global variables\n",
    "columns_to_drop = ['Id', 'Response'] #, 'Medical_History_10','Medical_History_24']\n",
    "xgb_num_rounds = 720\n",
    "missing_indicator = -1000\n",
    "\n",
    "# training and testing temp dataframes\n",
    "temp_train = train\n",
    "temp_test = test\n",
    "\n",
    "# getting all of the data\n",
    "all_data = pd.concat([temp_train, temp_test], ignore_index=True)\n",
    "\n",
    "# create new variable for product first and second character\n",
    "all_data['Product_Info_2'] = all_data.Product_Info_2.astype(str)\n",
    "all_data['Product_Info_2_char'] = all_data[\"Product_Info_2\"].str[0]\n",
    "all_data['Product_Info_2_num'] = all_data[\"Product_Info_2\"].str[1]\n",
    "\n",
    "# factorize the categorical variables\n",
    "all_data['Product_Info_2'] = pd.factorize(all_data['Product_Info_2'])[0]\n",
    "all_data['Product_Info_2_char'] = pd.factorize(all_data['Product_Info_2_char'])[0]\n",
    "all_data['Product_Info_2_num'] = pd.factorize(all_data['Product_Info_2_num'])[0]\n",
    "\n",
    "# get the combined BMI age variable\n",
    "all_data['BMI_Age'] = all_data['BMI'] * all_data['Ins_Age']\n",
    "\n",
    "# checking for how many medical keywords were found in each patient diagnosis\n",
    "med_keyword_columns = all_data.columns[all_data.columns.str.startswith('Medical_Keyword_')]\n",
    "all_data['Med_Keywords_Count'] = all_data[med_keyword_columns].sum(axis=1)\n",
    "\n",
    "# remove the missing values\n",
    "print('Eliminate missing values')    \n",
    "all_data.fillna(missing_indicator, inplace=True)\n",
    "\n",
    "# fix the dtype on the label column\n",
    "all_data['Response'] = all_data['Response'].astype(int)\n",
    "\n",
    "# split train and test\n",
    "train = all_data[all_data['Response']>0].copy()\n",
    "test = all_data[all_data['Response']<1].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving data from loader: 100%|██████████| 743/743 [00:00<00:00, 1507.17it/s]\n",
      "Retrieving data from loader: 100%|██████████| 186/186 [00:00<00:00, 1578.52it/s]\n",
      "Retrieving data from loader: 100%|██████████| 309/309 [00:00<00:00, 1582.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing theoretical clustering centroids...\n"
     ]
    }
   ],
   "source": [
    "# now create a neural network without any of the explainability features that we want to integrate\n",
    "\n",
    "# just pull the data from before\n",
    "train_data = all_data[all_data['Response'] > 0].copy()\n",
    "test_data = all_data[all_data['Response'] < 1].copy()\n",
    "\n",
    "# split the data into training and validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train_data.drop(columns=columns_to_drop, axis=1),\n",
    "    train_data['Response'],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# scale the data appropriately\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# fit and transform the data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# load the insurance dataset in \n",
    "class InsuranceDataset(Dataset):\n",
    "\n",
    "    # initialize the features and the labels\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    # define the length function\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    # get the item defined by an index\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.features[idx], dtype=torch.float), torch.tensor(self.labels[idx], dtype=torch.long) - 1  # Assuming labels are 1-indexed\n",
    "\n",
    "\n",
    "# define an object for the insurance test and train datasets\n",
    "train_dataset = InsuranceDataset(X_train_scaled, y_train.values)\n",
    "val_dataset = InsuranceDataset(X_val_scaled, y_val.values)\n",
    "test_dataset = train_dataset\n",
    "\n",
    "# include the validation dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = test_dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# compute the principal components of the data that we are trying to train the machine learning model on \n",
    "# all_data: this is all of the data that we are going to run the principal component analysis on\n",
    "# n_components: the number of components that the PCA should generate for us\n",
    "# should_scale: this defines whether we should scale the data that we are considering or not using the standard scaler\n",
    "def compute_PCA(all_data, n_components=10, scale_data=False):\n",
    "\n",
    "    # check the data type to make sure that it is good\n",
    "    if not isinstance(all_data, torch.Tensor):\n",
    "        all_data = torch.tensor(all_data, dtype=torch.float)\n",
    "\n",
    "    # compute the principal components\n",
    "    if scale_data:\n",
    "        std_scaler = StandardScaler()\n",
    "        all_data = std_scaler.fit_transform(all_data)\n",
    "\n",
    "    # run the pca\n",
    "    pca = PCA(n_components=n_components)\n",
    "    principal_components = pca.fit_transform(all_data)\n",
    "\n",
    "    # return the principal components\n",
    "    return pca, torch.from_numpy(principal_components).float()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# function for getting all of the features of the data together for computation\n",
    "def get_all_features(train_loader):\n",
    "\n",
    "    # get the matrix that we are going to be using to compute the mahalanobis distance\n",
    "    # start by getting all of the data from the loader\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    for features, labels in tqdm(train_loader, desc=\"Retrieving data from loader\"):\n",
    "        features_list.append(features)\n",
    "        labels_list.append(labels)\n",
    "\n",
    "    # concatenate all of the inputs that we are going to be using together\n",
    "    all_features = torch.cat(features_list, dim=0)\n",
    "\n",
    "    # get a tensor out of it\n",
    "    all_features = all_features.clone().detach()\n",
    "    \n",
    "    # concatenate all of the inputs that we are going to be using together\n",
    "    all_labels = torch.cat(labels_list, dim=0)\n",
    "    all_labels = all_labels.clone().detach()\n",
    "\n",
    "    return (all_features, all_labels)\n",
    "\n",
    "\n",
    "# function to visualize the PCA so that we can better understand the data that we are training on\n",
    "def visualize_pca(pca_features, labels, centroids):\n",
    "\n",
    "    # transfer the labels to numpy\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    # class colors\n",
    "    matplotlib_colors = [\n",
    "        'b',  \n",
    "        'g',  \n",
    "        'r',  \n",
    "        'c',  \n",
    "        'm',  \n",
    "        'y',  \n",
    "        'orange',\n",
    "        'purple',\n",
    "        'brown',\n",
    "        'pink',\n",
    "        'gray',\n",
    "        'olive',\n",
    "        'cyan',\n",
    "        'lime',\n",
    "        'maroon',\n",
    "        'navy',\n",
    "        'teal',\n",
    "        'coral'\n",
    "    ]\n",
    "\n",
    "    # get the number of labels that we are going to plot\n",
    "    # print(f\"Number of labels: {len(set(labels))}\")\n",
    "\n",
    "    # get the number of components that we are ploting\n",
    "    num_components = pca_features.shape[1]\n",
    "    num_plots = num_components // 3\n",
    "\n",
    "    # create subplots\n",
    "    for plot_index in range(num_plots):\n",
    "        fig = plt.figure(figsize=(10, 8))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "        # getting the compoennts that we ar egoing to be plotting\n",
    "        component_start = plot_index * 3\n",
    "        component_end = component_start + 3\n",
    "\n",
    "        # create the figure\n",
    "        fig = go.Figure()\n",
    "\n",
    "        # plot the PCA figures\n",
    "        for label in tqdm(set(labels), desc=f\"Plotting labeled data points in subplot {plot_index}\"):\n",
    "\n",
    "            # get all of the points from a certain label\n",
    "            indices = np.where(labels == label)[0]\n",
    "\n",
    "            # sample a maximum number of the points\n",
    "            if len(indices) > MAX_INDICIES_LEN_PLOTTING:\n",
    "                indices = np.random.choice(indices, MAX_INDICIES_LEN_PLOTTING, replace=False)\n",
    "\n",
    "            # print(f\"Plotting {len(indices)} points for label {label} in subplot {plot_index}...\")\n",
    "\n",
    "            # fix the label features to fix it if we had too. many\n",
    "            label_features = pca_features[indices, component_start:component_end]\n",
    "\n",
    "            # plot the dots\n",
    "            try:\n",
    "                # plt.scatter(label_features[:, 0], \n",
    "                #             label_features[:, 1], \n",
    "                #             color=matplotlib_colors[label], \n",
    "                #             label=f'Class {label}', \n",
    "                #             s=10)\n",
    "\n",
    "                fig.add_trace(go.Scatter3d(\n",
    "                    x=label_features[:, 0], \n",
    "                    y=label_features[:, 1], \n",
    "                    z=label_features[:, 2],\n",
    "                    mode='markers',\n",
    "                    marker=dict(size=3),\n",
    "                    name=f'Class {label}'\n",
    "                ))\n",
    "            except Exception as e:\n",
    "                print(f\"Failed: {e}\")\n",
    "        \n",
    "        # plot the centroids to show where they are\n",
    "        for i, centroid in enumerate(centroids):\n",
    "            if centroid.shape[0] > component_end:\n",
    "                fig.add_trace(go.Scatter3d(\n",
    "                    x=[centroid[component_start]],\n",
    "                    y=[centroid[component_start+1]],\n",
    "                    z=[centroid[component_start+2]],\n",
    "                    mode='markers',\n",
    "                    marker=dict(symbol='x', size=5, color='black'),\n",
    "                    name=f'Centroid {i + 1}'\n",
    "                ))\n",
    "                # print(f'Centroid {i + 1} at {centroid[component_start]} {centroid[component_start+1]} {centroid[component_start+2]}')\n",
    "\n",
    "        # put the information on the plots\n",
    "        # ax.set_title(f'3D PCA Plot of Components {component_start+1} to {component_end}')\n",
    "        # ax.set_xlabel('Component {}'.format(component_start + 1))\n",
    "        # ax.set_ylabel('Component {}'.format(component_start + 2))\n",
    "        # ax.set_zlabel('Component {}'.format(component_start + 3))\n",
    "        # ax.legend()\n",
    "\n",
    "        fig.update_layout(\n",
    "            title=f'3D PCA Plot of Components {component_start+1} to {component_end}',\n",
    "            scene=dict(\n",
    "                xaxis_title=f'Component {component_start + 1}',\n",
    "                yaxis_title=f'Component {component_start + 2}',\n",
    "                zaxis_title=f'Component {component_start + 3}'\n",
    "            ),\n",
    "            legend_title=\"Legend\",\n",
    "            autosize=False,\n",
    "            width=700,\n",
    "            height=700,\n",
    "        )\n",
    "\n",
    "        # plot the title as neede\n",
    "        # plt.title('PCA of Training Data')\n",
    "        # plt.xlabel('Principal Component 1')\n",
    "        # plt.ylabel('Principal Component 2')\n",
    "        # plt.legend()\n",
    "        # plt.grid(True)\n",
    "        fig.show()\n",
    "\n",
    "        # now save the plot to a png\n",
    "        # fig.write_image(os.path.join(HOME_DIR, SUB_DIR, GENERATED_IMAGES_DIR, f\"pca_subplot_{plot_index}.png\"))\n",
    "\n",
    "        # display the image\n",
    "        # display(Image(filename=os.path.join(HOME_DIR, SUB_DIR, GENERATED_IMAGES_DIR, f\"pca_subplot_{plot_index}.png\")))\n",
    "\n",
    "\n",
    "\n",
    "# prepare the test data (normalize and load into DataLoader)\n",
    "X_test_scaled = scaler.transform(test_data.drop(columns=['Response', 'Id'] + columns_to_drop, axis=1))\n",
    "test_dataset = InsuranceDataset(X_test_scaled, np.zeros((X_test_scaled.shape[0],)))\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "# getting all of the data\n",
    "(all_train_features, all_train_labels) = get_all_features(train_loader)\n",
    "(all_val_features, all_val_labels) = get_all_features(val_loader)\n",
    "(all_test_features, all_test_labels) = get_all_features(test_loader)\n",
    "\n",
    "\n",
    "# pca_model, pca_train_features = compute_PCA(all_train_features)\n",
    "# pca_val_features = torch.from_numpy(pca_model.transform(all_val_features)).float()\n",
    "\n",
    "# saving the model if we have trained it\n",
    "# if TRAIN_MODEL:\n",
    "   \n",
    "# run PCA on the data\n",
    "pca_model, pca_train_features = compute_PCA(all_train_features)\n",
    "pca_val_features = torch.from_numpy(pca_model.transform(all_val_features)).float()\n",
    "pca_test_features = torch.from_numpy(pca_model.transform(all_test_features)).float()\n",
    "\n",
    "# else:\n",
    "   \n",
    "    # load the PCA model in \n",
    "    # pca_model = joblib.load(os.path.join(curr_run_dir, 'pca_model.joblib'))\n",
    "\n",
    "# # check if we should save the model to a runthrough\n",
    "# if SHOULD_SAVE_OUTPUT:\n",
    "#     print(f\"Saving PCA\")\n",
    "#     joblib.dump(pca_model, os.path.join(curr_run_dir, 'pca_model.joblib'))\n",
    "\n",
    "\n",
    "\n",
    "# checking the shapes\n",
    "# print(f\"all_train_features shape: {all_train_features.shape}\")\n",
    "# print(f\"pca_components shape: {pca_train_features.shape}\")\n",
    "# print(f\"inverse transform shape: {pca_model.inverse_transform(pca_train_features).shape}\")\n",
    "# print(f\"all_train_labels shape: {all_train_labels.shape}\")\n",
    "\n",
    "# turn the training data into a dataset\n",
    "pca_train_loader = TensorDataset(pca_train_features, all_train_labels)\n",
    "pca_val_loader = TensorDataset(pca_val_features, all_val_labels)\n",
    "pca_test_loader = TensorDataset(pca_test_features, all_test_labels)\n",
    "\n",
    "# define the loaders\n",
    "pca_train_loader = DataLoader(pca_train_loader, batch_size=BATCH_SIZE, shuffle=True)\n",
    "pca_val_loader = DataLoader(pca_val_loader, batch_size=BATCH_SIZE, shuffle=False)\n",
    "pca_test_loader = DataLoader(pca_test_loader, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "if TRAIN_PCA:\n",
    "    train_loader = pca_train_loader\n",
    "    test_loader = pca_test_loader\n",
    "    val_loader = pca_val_loader\n",
    "\n",
    "\n",
    "t_input, _ = next(iter(train_loader))\n",
    "t_input_shape = t_input.shape[1]\n",
    "\n",
    "# now get the k centroids that would represent the center of the clusters that\n",
    "# I would get if I ran a k-means clustering algorithm\n",
    "print(f\"Computing theoretical clustering centroids...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# these are helper functions that help us to monitor the output of the neural network layers and \n",
    "# attach hooks to the neural network that helps us get the forward pass values\n",
    "influence_network_layer_outputs = []\n",
    "influence_network_current_pass_through = []\n",
    "\n",
    "# define the hook to get the forward pass through the neural network\n",
    "def node_importance_get_layer_output_hook(module, input, output):\n",
    "\n",
    "    global influence_network_current_pass_through\n",
    "\n",
    "    # append the output of this passthrough to the total array\n",
    "    influence_network_current_pass_through.append(output.cpu().detach())  \n",
    "\n",
    "# register the hooks with the network\n",
    "def node_importance_register_hooks(model):\n",
    "\n",
    "    # print(f\"Registering hooks...\")\n",
    "\n",
    "    # check each of the layers for somewhere where we can register a hook\n",
    "    for layer in model.children():\n",
    "\n",
    "        # check for an instance of a layer\n",
    "        if isinstance(layer, nn.Module):\n",
    "\n",
    "            # register a forward hook\n",
    "            layer.register_forward_hook(node_importance_get_layer_output_hook)\n",
    "\n",
    "            # give the staus\n",
    "            # print(f\"Registered a forward hook at: {layer}\")\n",
    "\n",
    "# start a new pass of the model that we are running with specified inputs\n",
    "def node_importance_start_new_pass_through_with_input(inputs):\n",
    "    global influence_network_current_pass_through\n",
    "    influence_network_current_pass_through = [inputs]\n",
    "\n",
    "# start a new pass of the model that we are running\n",
    "def node_importance_start_new_pass_through():\n",
    "    global influence_network_current_pass_through\n",
    "    influence_network_current_pass_through = []\n",
    "\n",
    "# clear the current pass through\n",
    "def node_importance_save_and_clear_influence_network_current_pass_through():\n",
    "    global influence_network_layer_outputs, influence_network_current_pass_through\n",
    "    influence_network_layer_outputs.append(influence_network_current_pass_through)\n",
    "\n",
    "    node_importance_start_new_pass_through()\n",
    "\n",
    "# this function entirely wipes the storage of the intermediate values\n",
    "def node_importance_clear_total_run():\n",
    "    global influence_network_layer_outputs\n",
    "    influence_network_layer_outputs = []\n",
    "\n",
    "# function to return and clear the entire training series\n",
    "def node_importance_retrieve_and_return_entire_network_outputs():\n",
    "    global influence_network_layer_outputs\n",
    "    t_ret = influence_network_layer_outputs\n",
    "    influence_network_layer_outputs = []\n",
    "    return t_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network for the insurance dataset\n",
    "# as a baseline for the model\n",
    "class InsuranceNN(nn.Module):\n",
    "\n",
    "    # initialize the insurance neural network item\n",
    "    def __init__(self):\n",
    "        super(InsuranceNN, self).__init__()\n",
    "        self.foward_1 = nn.Linear(t_input_shape, 32)\n",
    "        self.foward_2 = nn.Linear(32, 16)\n",
    "        self.foward_3 = nn.Linear(16, NUM_CLASSES)  \n",
    "\n",
    "    # go forward through the neural network\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.foward_1(x))\n",
    "        x = F.relu(self.foward_2(x))\n",
    "        x = self.foward_3(x)\n",
    "        return x\n",
    "\n",
    "# initialize the model\n",
    "baseline_model = InsuranceNN()\n",
    "\n",
    "# register the hooks that are going to keep track of the outputs of the model activations\n",
    "# register_hooks(baseline_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start of Importance Reduction Formula\n",
    "\n",
    "This is the start of the development of the importance reduction equation which will lower the importance of certain inputs to the network. We are going to try a series of analyses to try to understand how to optimally remove the influence of a single input on the neural network that we are considering. We are going to try to find how long each of the methods that we detail takes along with the degradation in accuracy compared to baseline. Some methods that we plan to explore are below, but there likely will not be enough time to explore all of the method:\n",
    "\n",
    "- simple retraining: this is going to serve as the baseline that we compare the rest of the methdos that we try against. We are going to remove one of the inputs from the model, and train the model to see how the model does along with how long it takes. \n",
    "- stochastic fine-tuning: this method takes the original dataset and fine-tunes the model where the input feature that we are trying to mask has a stochastic value in place of the real value for each instance that we process in the dataset.\n",
    "- inversion fine-tuning: similar to the stochastic method, this method takes the input tensors that we used to originally train the model but changes the feature that we are trying to remove to an inverted version of the original data point. That is, given the original datapoint feature $x$ and the mean of the feature over the entire dataset $x'$, we fine-tune the model using the save input data but with x changed to $x = x - 2 \\cdot (x - x')$. We explore whether using the mean is the optimal configuration as well. \n",
    "- amplitude-influence reduction: in this method, we actually manipulate the weights of the model to try to approximate the original output of the model while enforcing all weights coming out of the node that we target in the model remain equal to 0. If the node that we are tring to limit the influence of is an input node, then we can fine-tune the model after to ensure that the output is approximated as closely as possible. Otherwise, we simply have to keep the model as is after the weight manipulation or the concept could become dispersed through other nodes and flow to a later layer. One way to improve the effectiveness of this method would be to use the covariance of the individual activations from layer $i-1$ to supplement the removal of a single node in layer $i-1$ totally. In order to do this, I find the covariance of all of the outputs of the layer and greedily add influenece from the nodes that have the highest magnitude covariance on all of the outputs that have lost the influence of the selected node. I adjust the bias in the process if possible as well. Please note that the code below hardcodes the influence function for the first layer, but this can be changed with some adjustments. Additionally, because of the nature of PCA, this function does not perform well with the PCA loader. \n",
    "\n",
    "I start with simply trying to remove the influence of one of the inputs to the model. If there is time, I will extend this to deeper layers of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.652850169833865, Val Loss: 1.5662120978037517\n",
      "Epoch 2, Loss: 1.5410764132341819, Val Loss: 1.544677339574342\n",
      "Epoch 3, Loss: 1.526125274147352, Val Loss: 1.5348572615654237\n",
      "Epoch 4, Loss: 1.5177218339645364, Val Loss: 1.5290674496722478\n",
      "Epoch 5, Loss: 1.5121218984893963, Val Loss: 1.525150143331097\n",
      "Epoch 6, Loss: 1.5071131603875039, Val Loss: 1.5218099887653063\n",
      "Epoch 7, Loss: 1.5038742152710782, Val Loss: 1.5208440352511663\n",
      "Epoch 8, Loss: 1.5014045105327025, Val Loss: 1.5173352008224816\n",
      "Epoch 9, Loss: 1.498851070654344, Val Loss: 1.5178921222686768\n",
      "Epoch 10, Loss: 1.4969576348526803, Val Loss: 1.5157328747933911\n",
      "Epoch 11, Loss: 1.4955074533639654, Val Loss: 1.5144329583773048\n",
      "Epoch 12, Loss: 1.4935335610788891, Val Loss: 1.5097157948760576\n",
      "Epoch 13, Loss: 1.4917428952367278, Val Loss: 1.5093988154524116\n",
      "Epoch 14, Loss: 1.4902906878318634, Val Loss: 1.508205613782329\n",
      "Epoch 15, Loss: 1.4877887691495235, Val Loss: 1.5085957332323956\n",
      "Epoch 16, Loss: 1.4869215645668163, Val Loss: 1.5082575544234245\n",
      "Epoch 17, Loss: 1.4856977491648329, Val Loss: 1.506014012521313\n",
      "Epoch 18, Loss: 1.4849530941384317, Val Loss: 1.5026999961945318\n",
      "Epoch 19, Loss: 1.4836159313992567, Val Loss: 1.5029501094613025\n",
      "Epoch 20, Loss: 1.4825810840601554, Val Loss: 1.5053062900420158\n",
      "Epoch 21, Loss: 1.482001045189828, Val Loss: 1.5018643102338236\n",
      "Epoch 22, Loss: 1.4813528851898008, Val Loss: 1.5029745838975395\n",
      "Epoch 23, Loss: 1.4812257410218868, Val Loss: 1.5022676939605384\n",
      "Epoch 24, Loss: 1.4803706433217907, Val Loss: 1.5017819616102404\n",
      "Epoch 25, Loss: 1.4794561532432586, Val Loss: 1.5050926849406252\n",
      "Epoch 26, Loss: 1.4796573064850285, Val Loss: 1.5055269278505796\n",
      "Stopping early due to increasing validation loss.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start by defining a model that we are going to analyze and change\n",
    "\n",
    "##\n",
    "# this function is used to train the neural network that we are going to be using for classification of the items that \n",
    "# we are considering for insurance and for prisoners\n",
    "def train_model(model, train_loader, val_loader, loss_function, optimizer, epochs=10, patience=2):\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    # lists to store loss values for plotting\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    epochs_list = []\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = loss_function(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_val_loss = val_loss / len(val_loader)\n",
    "        # print(f'Epoch {epoch+1}, Loss: {epoch_loss}, Val Loss: {epoch_val_loss}')\n",
    "\n",
    "        train_losses.append(epoch_loss)\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        epochs_list.append(epoch + 1)\n",
    "\n",
    "        # check if the validation loss improved\n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "            patience_counter = 0\n",
    "        \n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        # check for early stopping\n",
    "        if patience_counter > patience:\n",
    "            print(\"Stopping early due to increasing validation loss.\")\n",
    "            break\n",
    "\n",
    "        # print the statistics from this epoch\n",
    "        print(f'Epoch {epoch+1}, Loss: {epoch_loss}, Val Loss: {epoch_val_loss}')\n",
    "\n",
    "    # plotting the training and validation loss\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs_list, train_losses, label='Training Loss', color=PLOT_COLOR_1)\n",
    "    plt.plot(epochs_list, val_losses, label='Validation Loss', color=PLOT_COLOR_2)\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    if SHOULD_SAVE_OUTPUT:\n",
    "        plt.savefig(os.path.join(WRITE_DIR, \"nn_loss.png\"))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# define the loss function and optimizer that we are going to be using to train the neural network\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(baseline_model.parameters(), lr=0.001)\n",
    "\n",
    "# training the model\n",
    "train_model(baseline_model, train_loader, val_loader, loss_function, optimizer, epochs=30)\n",
    "\n",
    "# saving the model to a state dictionary\n",
    "torch.save(baseline_model, os.path.join(WRITE_DIR, BASELINE_SAVE_FILE_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial importance of feature 7 in layer 0:\n",
      "0 : 10 | 1.00\n",
      "1 : 32 | 1.00\n",
      "2 : 16 | 1.00\n",
      "Importance to output: 0.1268400400876999\n",
      "\n",
      "[0.1388101  0.09843887 0.12981972 0.09996457 0.07852222 0.12684004\n",
      " 0.08320011 0.07811422 0.08963289 0.07665721]\n"
     ]
    }
   ],
   "source": [
    "# starting from index zero for each\n",
    "# this is the last PCA component\n",
    "# in the first layer\n",
    "FEATURE_NUM = 7\n",
    "LAYER_NUM = 0\n",
    "\n",
    "\n",
    "# this function computes the relevance of a single node+feature combination in the neural network\n",
    "# layer_num: this is the layer number of the node that we are targeting\n",
    "# feature_num: the number of the node that we want to minimize the importance of\n",
    "# def compute_single_feature_importance(input_model, data_loader, layer_num, feature_num):\n",
    "def compute_importance_GRAD(input_model, data_loader):\n",
    "\n",
    "\t# go through and get the one-hot importance of each input\n",
    "\tloss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "\t# setting model to train\n",
    "\tinput_model.train()\n",
    "\t\t\n",
    "\t# array to keep track of all of the gradients in the model\n",
    "\ttotal_gradient_list = None\n",
    "\n",
    "\t# the number of batches that we consider\n",
    "\tnumber_considered = 0\n",
    "\n",
    "\t# compute the gradients\n",
    "\tfor input_data, input_label in data_loader:\n",
    "\t\t\n",
    "\t\t# keep track of the gradients of this instance\n",
    "\t\tinstance_grads = []\n",
    "\n",
    "\t\t# set the gradients of the model to zero\n",
    "\t\tinput_model.zero_grad()\n",
    "\n",
    "\t\t# get the output from the model\n",
    "\t\tmodel_guess = input_model(input_data)\n",
    "\n",
    "\t\t# compute the loss\n",
    "\t\tr_loss = loss_func(model_guess, input_label)\n",
    "\n",
    "\t\t# backpropagate the error\n",
    "\t\tr_loss.backward()\n",
    "\n",
    "\t\t# keep track of the gradients\n",
    "\t\tfor name, param in input_model.named_parameters():\n",
    "\n",
    "\t\t\t# check if this is something that we should consider\n",
    "\t\t\tif 'weight' in name and param.grad is not None:\n",
    "\n",
    "\t\t\t\t# store the abs gradients\n",
    "\t\t\t\t# print(f\"Grad shpae: {param.grad.abs().shape}\")\n",
    "\t\t\t\tinstance_grads.append(param.grad.abs() * param.data.abs())\n",
    "\t\t\t\t\n",
    "\t\t\t\t# if param.data.abs().shape == (32, 10):\n",
    "\t\t\t\t# \tprint(param.grad.abs())\n",
    "\t\t\t\t# \tprint(param.data.abs())\n",
    "\t\t\t\t# \tprint(instance_grads[-1])\n",
    "\t\t\t\t# \t# print('hi')\n",
    "\t\t\t\t# \treturn\n",
    "\n",
    "\n",
    "\t\t# check if this is an empty list\n",
    "\t\tif total_gradient_list is None:\n",
    "\n",
    "\t\t\t# add all of the gradients together\n",
    "\t\t\ttotal_gradient_list = []\n",
    "\n",
    "\t\t\tfor l_idx, instance_entry in enumerate(instance_grads):\n",
    "\n",
    "\t\t\t\t# create zero versions of all of the gradient entries\n",
    "\t\t\t\ttotal_gradient_list.append(torch.zeros_like(instance_entry.mean(dim=0)))\n",
    "\n",
    "\t\t# update the total gradient list\n",
    "\t\tfor l_idx, instance_entry in enumerate(instance_grads):\n",
    "\n",
    "\t\t\t# add the mean of the gradient\n",
    "\t\t\t# total_gradient_list[l_idx] += torch.clamp(instance_entry, min=0).mean(dim=0)\n",
    "\t\t\t# print(instance_entry.shape)\n",
    "\t\t\t# print(torch.abs(instance_entry).mean(dim=0).shape)\n",
    "\t\t\t# print(instance_entry)\n",
    "\t\t\t# print(torch.abs(instance_entry).mean(dim=0))\n",
    "\t\t\t# print(l_idx)\n",
    "\t\t\ttotal_gradient_list[l_idx] += torch.abs(instance_entry).mean(dim=0)\n",
    "\n",
    "\t\t# increment the number of examples that we have considered\n",
    "\t\tnumber_considered += 1\n",
    "\n",
    "\t\t# if number_considered > 10:\n",
    "\t\t# \tprint(total_gradient_list)\n",
    "\t\t# \tbreak\n",
    "\n",
    "\t# average out the relevances\n",
    "\ttotal_gradient_list = [relevance / (number_considered) for relevance in total_gradient_list]\n",
    "\n",
    "\t# dot with the weights\n",
    "\n",
    "\t# normalize all of the layers\n",
    "\ttotal_gradient_list = [t_layer / t_layer.sum() for t_layer in total_gradient_list]\n",
    "\n",
    "\t# return the initial layer relevance\n",
    "\t# total_gradient_list.reverse()\n",
    "\treturn [r.cpu().numpy() for r in total_gradient_list]\t\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# define a function to get the importance of some input feature or node that we want to target\n",
    "# it effectively uses a method for layer relevance propagation\n",
    "# and takes the average relevance over all of the input data that we can give it\n",
    "# input_model: this is the model that we are going to compute the importance in \n",
    "def compute_importance_LRP(input_model, data_loader):\n",
    "\n",
    "\t# go through and get the one-hot importance of each input\n",
    "\t# loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "\tinput_model.eval()\n",
    "\n",
    "\t# go through and add the hooks that take care of logging the activations\n",
    "\t# and the outputs of the layers that we are considering\n",
    "\tlayer_activations = []\n",
    "\n",
    "\tall_layer_avg_relevances = None\n",
    "\tnumber_considered = 0\n",
    "\n",
    "\t# this adds a hook to each layer of the model to get the activation\n",
    "\tdef forward_hook(module, input, output):\n",
    "\n",
    "\t\t# add to the linear and relus only\n",
    "\t\tif isinstance(module, nn.ReLU) or isinstance(module, nn.Linear):\n",
    "\t\t\tlayer_activations.append(output)\n",
    "\n",
    "\n",
    "\t# add the hooks to the model\n",
    "\tmodel_layer_hooks = []\n",
    "\n",
    "\t# iterate the layers\n",
    "\tfor layer in input_model.modules():\n",
    "\n",
    "\t\tif isinstance(layer, nn.ReLU) or isinstance(layer, nn.Linear):\n",
    "\t\t\t\n",
    "\t\t\t# register the hook\n",
    "\t\t\tt_hook = layer.register_forward_hook(forward_hook)\n",
    "\t\t\tmodel_layer_hooks.append(t_hook)\n",
    "\n",
    "\n",
    "\t# setting model to train\n",
    "\tinput_model.train()\n",
    "\t\t\n",
    "\t# array to keep track of all of the gradients in the model\n",
    "\ttotal_gradient_list = []\n",
    "\n",
    "\t# compute the gradients\n",
    "\tfor input_data, input_label in data_loader:\n",
    "\n",
    "\t\t# set the gradients of the model to zero\n",
    "\t\tinput_model.zero_grad()\n",
    "\n",
    "\t\t# # get the output from the model\n",
    "\t\t# model_guess = input_model(input_data)\n",
    "\n",
    "\t\t# # compute the loss\n",
    "\t\t# r_loss = loss_func(model_guess, input_label)\n",
    "\n",
    "\t\t# # backpropagate the error\n",
    "\t\t# r_loss.backward()\n",
    "\n",
    "\t\t# # keep track of the gradients\n",
    "\t\t# for param in input_model.parameters():\n",
    "\t\t\t\t\n",
    "\t\t# \t\t# check if this is something that we should consider\n",
    "\t\t# \t\tif param.grad is not None:\n",
    "\t\t\t\t\t\n",
    "\t\t# \t\t\t# store the abs gradients\n",
    "\t\t# \t\t\ttotal_gradient_list.append(param.grad.abs())\n",
    "\n",
    "\t\t# get no gradient\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\t\n",
    "\t\t\t# get the output from the model\n",
    "\t\t\tmodel_guess = input_model(input_data)\n",
    "\t\t\n",
    "\t\t# now get the relevance with respect to this input and update the mean values\n",
    "\t\tlayer_relevance = model_guess\n",
    "\t\tinstance_total_layer_activations = [layer_relevance.clone().mean(dim=0)]\n",
    "\n",
    "\t\t\n",
    "\t\t# # initialize all of the relevances if this has not been called yet\n",
    "\t\t# if all_layer_avg_relevances is None:\n",
    "\t\t# \tall_layer_avg_relevances = [torch.zeros_like(act) for act in layer_activations]\n",
    "\n",
    "\t\t# getting the number of activations\n",
    "\t\t# print(f\"Number of layer activations: {len(layer_activations)}\")\n",
    "\t\t\n",
    "\n",
    "\t\t# iterate through all of the possible activations in the model\n",
    "\t\tfor i in range(len(layer_activations)-1, -1, -1):\n",
    "\n",
    "\t\t\t# print(f\"Checking layer {i}\")\n",
    "\n",
    "\t\t\t# get the current and previous activations to get the relevance\n",
    "\t\t\tcurrent_activation = layer_activations[i]\n",
    "\t\t\tprevious_activation = layer_activations[i-1] if i > 0 else input_data\n",
    "\n",
    "\t\t\t# get the current layer of the model\n",
    "\t\t\tcurrent_layer = list(input_model.children())[i]\n",
    "\n",
    "\t\t\t# look for the linear weights to propagate the relevance\n",
    "\t\t\tif isinstance(current_layer, nn.Linear):\n",
    "\t\t\t\t\n",
    "\t\t\t\t# get the weights of the model\n",
    "\t\t\t\tweights = current_layer.weight.data\n",
    "\n",
    "\t\t\t\t# this applies the z-rule to the layer to compute the resulting relevances\n",
    "\t\t\t\t# print(f\"processing: {previous_activation.shape} {torch.clamp(weights, min=0).T.shape}\")\n",
    "\t\t\t\tz_rule_z_val = torch.matmul(previous_activation, torch.clamp(weights, min=0).T) + 1e-10\n",
    "\t\t\t\tz_rule_s_val = layer_relevance / z_rule_z_val\n",
    "\t\t\t\tz_rule_c_val = torch.matmul(z_rule_s_val, torch.clamp(weights, min=0))\n",
    "\t\t\t\t\n",
    "\t\t\t\t# propagate relevance to the previous layer\n",
    "\t\t\t\tlayer_relevance = previous_activation * z_rule_c_val \n",
    "\t\t\t\t\n",
    "\t\t\t\t# print(f\"previous_activation length: {len(previous_activation)}\")\n",
    "\t\t\t\t# print(f\"z_rule_c_val: {z_rule_c_val.shape}\")\n",
    "\t\t\t\t# print(f\"layer_relevance shape: {layer_relevance.mean(dim=0).shape}\")\n",
    "\n",
    "\t\t\t# add the relevance to the array\n",
    "\t\t\tinstance_total_layer_activations.append(layer_relevance.mean(dim=0))\n",
    "\n",
    "\t\t\n",
    "\t\t\n",
    "\t\t# if we have not added anything then just make these values the relevance values\n",
    "\t\tif not all_layer_avg_relevances:\n",
    "\t\t\t# all_layer_avg_relevances = instance_total_layer_activations\n",
    "\t\t\tall_layer_avg_relevances = [torch.zeros_like(a) for a in instance_total_layer_activations]\n",
    "\t\t\n",
    "\t\t# otherwise then compute the new averages\n",
    "\t\tfor l_idx, layer_rel in enumerate(instance_total_layer_activations):\n",
    "\t\t\t\n",
    "\t\t\t# print(f\"{instance_total_layer_activations[l_idx].shape}\")\n",
    "\t\t\tall_layer_avg_relevances[l_idx] += layer_rel.mean(dim=0)\n",
    "\n",
    "\t\t# increment the number of examples that we have considered\n",
    "\t\tnumber_considered += 1\n",
    "\n",
    "\t\t# clear the layer activations\n",
    "\t\tlayer_activations.clear()\n",
    "\n",
    "\t# average out the relevances\n",
    "\tdat, _ = next(iter(data_loader))\n",
    "\tbatch_size = dat.shape[0]\n",
    "\tall_layer_avg_relevances = [relevance / (number_considered) for relevance in all_layer_avg_relevances]\n",
    "\n",
    "\n",
    "\t# remove all of the hooks from the model\n",
    "\tfor t_hook in model_layer_hooks:\n",
    "\t\tt_hook.remove()\n",
    "\n",
    "\t# return the initial layer relevance\n",
    "\tall_layer_avg_relevances.reverse()\n",
    "\treturn [r.cpu().numpy() for r in all_layer_avg_relevances]\t\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# first bit of importance computation\n",
    "initial_importance = compute_importance_GRAD(baseline_model, train_loader)\n",
    "print(f\"Initial importance of feature {FEATURE_NUM} in layer {LAYER_NUM}:\")\n",
    "\n",
    "for l_num in range(len(initial_importance)):\n",
    "\tprint(f\"{l_num} : {len(initial_importance[l_num])} | {sum(initial_importance[l_num]):.2f}\")\n",
    "\n",
    "# print the importance\n",
    "print(f\"Importance to output: {initial_importance[0][5]}\")\n",
    "\n",
    "print()\n",
    "print(initial_importance[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n",
      "RESULTS FOR REMOVING FEATURE 0 INFLUENCE:\n",
      "Removing influence with greedy_amplitude_correlation_adjustment\n",
      "Took 3.6363 seconds on average for\n",
      "avg_train_loss: 1.4848 (0.67%)\n",
      "avg_val_loss: 1.5313 (1.90%)\n",
      "importance: 0.0000 (-100.00%)\n",
      "\n",
      "Removing influence with stochastic_fine_tuning\n",
      "Took 3.1858 seconds on average for\n",
      "avg_train_loss: 1.4973 (1.55%)\n",
      "avg_val_loss: 1.5212 (1.23%)\n",
      "importance: 0.0273 (-65.93%)\n",
      "\n",
      "Removing influence with inversion_fine_tuning\n",
      "Took 3.2662 seconds on average for\n",
      "avg_train_loss: 1.4832 (0.56%)\n",
      "avg_val_loss: 1.5035 (0.05%)\n",
      "importance: 0.0620 (-22.73%)\n",
      "\n",
      "Removing influence with simple_retraining\n",
      "Took 16.9821 seconds on average for\n",
      "avg_train_loss: 1.4954 (1.43%)\n",
      "avg_val_loss: 1.5177 (0.99%)\n",
      "importance: 0.0000 (-100.00%)\n",
      "\n",
      "\n",
      "RESULTS FOR REMOVING FEATURE 1 INFLUENCE:\n",
      "Removing influence with greedy_amplitude_correlation_adjustment\n",
      "Took 3.5472 seconds on average for\n",
      "avg_train_loss: 1.4847 (0.67%)\n",
      "avg_val_loss: 1.5306 (1.85%)\n",
      "importance: 0.0000 (-100.00%)\n",
      "\n",
      "Removing influence with stochastic_fine_tuning\n",
      "Took 3.1915 seconds on average for\n",
      "avg_train_loss: 1.4979 (1.57%)\n",
      "avg_val_loss: 1.5208 (1.20%)\n",
      "importance: 0.0262 (-67.40%)\n",
      "\n",
      "Removing influence with inversion_fine_tuning\n",
      "Took 3.1951 seconds on average for\n",
      "avg_train_loss: 1.4832 (0.59%)\n",
      "avg_val_loss: 1.5049 (0.14%)\n",
      "importance: 0.0627 (-21.84%)\n",
      "\n",
      "Removing influence with simple_retraining\n",
      "Took 17.5760 seconds on average for\n",
      "avg_train_loss: 1.4966 (1.49%)\n",
      "avg_val_loss: 1.5220 (1.28%)\n",
      "importance: 0.0000 (-100.00%)\n",
      "\n",
      "\n",
      "RESULTS FOR REMOVING FEATURE 2 INFLUENCE:\n",
      "Removing influence with greedy_amplitude_correlation_adjustment\n",
      "Took 3.8185 seconds on average for\n",
      "avg_train_loss: 1.4851 (0.69%)\n",
      "avg_val_loss: 1.5307 (1.86%)\n",
      "importance: 0.0000 (-100.00%)\n",
      "\n",
      "Removing influence with stochastic_fine_tuning\n",
      "Took 3.1479 seconds on average for\n",
      "avg_train_loss: 1.4984 (1.62%)\n",
      "avg_val_loss: 1.5213 (1.23%)\n",
      "importance: 0.0252 (-68.57%)\n",
      "\n",
      "Removing influence with inversion_fine_tuning\n",
      "Took 3.1382 seconds on average for\n",
      "avg_train_loss: 1.4832 (0.59%)\n",
      "avg_val_loss: 1.5043 (0.10%)\n",
      "importance: 0.0614 (-23.48%)\n",
      "\n",
      "Removing influence with simple_retraining\n",
      "Took 17.0895 seconds on average for\n",
      "avg_train_loss: 1.4962 (1.45%)\n",
      "avg_val_loss: 1.5175 (0.98%)\n",
      "importance: 0.0000 (-100.00%)\n",
      "\n",
      "\n",
      "RESULTS FOR REMOVING FEATURE 3 INFLUENCE:\n",
      "Removing influence with greedy_amplitude_correlation_adjustment\n",
      "Took 3.3888 seconds on average for\n",
      "avg_train_loss: 1.4854 (0.75%)\n",
      "avg_val_loss: 1.5298 (1.80%)\n",
      "importance: 0.0000 (-100.00%)\n",
      "\n",
      "Removing influence with stochastic_fine_tuning\n",
      "Took 3.1253 seconds on average for\n",
      "avg_train_loss: 1.4978 (1.56%)\n",
      "avg_val_loss: 1.5221 (1.28%)\n",
      "importance: 0.0254 (-68.39%)\n",
      "\n",
      "Removing influence with inversion_fine_tuning\n",
      "Took 3.1620 seconds on average for\n",
      "avg_train_loss: 1.4837 (0.61%)\n",
      "avg_val_loss: 1.5036 (0.05%)\n",
      "importance: 0.0597 (-25.63%)\n",
      "\n",
      "Removing influence with simple_retraining\n",
      "Took 17.1359 seconds on average for\n",
      "avg_train_loss: 1.4985 (1.63%)\n",
      "avg_val_loss: 1.5246 (1.45%)\n",
      "importance: 0.0000 (-100.00%)\n",
      "\n",
      "\n",
      "RESULTS FOR REMOVING FEATURE 4 INFLUENCE:\n",
      "Removing influence with greedy_amplitude_correlation_adjustment\n",
      "Took 3.4444 seconds on average for\n",
      "avg_train_loss: 1.4843 (0.67%)\n",
      "avg_val_loss: 1.5325 (1.98%)\n",
      "importance: 0.0000 (-100.00%)\n",
      "\n",
      "Removing influence with stochastic_fine_tuning\n",
      "Took 3.0481 seconds on average for\n",
      "avg_train_loss: 1.4977 (1.55%)\n",
      "avg_val_loss: 1.5223 (1.30%)\n",
      "importance: 0.0251 (-68.70%)\n",
      "\n",
      "Removing influence with inversion_fine_tuning\n",
      "Took 3.1684 seconds on average for\n",
      "avg_train_loss: 1.4830 (0.54%)\n",
      "avg_val_loss: 1.5042 (0.09%)\n",
      "importance: 0.0611 (-23.88%)\n",
      "\n",
      "Removing influence with simple_retraining\n",
      "Took 17.3292 seconds on average for\n",
      "avg_train_loss: 1.4959 (1.43%)\n",
      "avg_val_loss: 1.5250 (1.48%)\n",
      "importance: 0.0000 (-100.00%)\n",
      "\n",
      "\n",
      "RESULTS FOR REMOVING FEATURE 5 INFLUENCE:\n",
      "Removing influence with greedy_amplitude_correlation_adjustment\n",
      "Took 3.5040 seconds on average for\n",
      "avg_train_loss: 1.4849 (0.67%)\n",
      "avg_val_loss: 1.5308 (1.86%)\n",
      "importance: 0.0000 (-100.00%)\n",
      "\n",
      "Removing influence with stochastic_fine_tuning\n",
      "Took 3.1389 seconds on average for\n",
      "avg_train_loss: 1.4977 (1.58%)\n",
      "avg_val_loss: 1.5216 (1.25%)\n",
      "importance: 0.0211 (-73.66%)\n",
      "\n",
      "Removing influence with inversion_fine_tuning\n",
      "Took 3.1627 seconds on average for\n",
      "avg_train_loss: 1.4834 (0.58%)\n",
      "avg_val_loss: 1.5042 (0.09%)\n",
      "importance: 0.0604 (-24.75%)\n",
      "\n",
      "Removing influence with simple_retraining\n",
      "Took 16.8710 seconds on average for\n",
      "avg_train_loss: 1.4946 (1.36%)\n",
      "avg_val_loss: 1.5172 (0.96%)\n",
      "importance: 0.0000 (-100.00%)\n",
      "\n",
      "\n",
      "RESULTS FOR REMOVING FEATURE 6 INFLUENCE:\n",
      "Removing influence with greedy_amplitude_correlation_adjustment\n",
      "Took 3.4048 seconds on average for\n",
      "avg_train_loss: 1.4851 (0.74%)\n",
      "avg_val_loss: 1.5308 (1.87%)\n",
      "importance: 0.0000 (-100.00%)\n",
      "\n",
      "Removing influence with stochastic_fine_tuning\n",
      "Took 3.0967 seconds on average for\n",
      "avg_train_loss: 1.4977 (1.58%)\n",
      "avg_val_loss: 1.5223 (1.30%)\n",
      "importance: 0.0274 (-65.87%)\n",
      "\n",
      "Removing influence with inversion_fine_tuning\n",
      "Took 3.3292 seconds on average for\n",
      "avg_train_loss: 1.4840 (0.61%)\n",
      "avg_val_loss: 1.5037 (0.06%)\n",
      "importance: 0.0616 (-23.23%)\n",
      "\n",
      "Removing influence with simple_retraining\n",
      "Took 16.6251 seconds on average for\n",
      "avg_train_loss: 1.4935 (1.29%)\n",
      "avg_val_loss: 1.5199 (1.14%)\n",
      "importance: 0.0000 (-100.00%)\n",
      "\n",
      "\n",
      "RESULTS FOR REMOVING FEATURE 7 INFLUENCE:\n",
      "Removing influence with greedy_amplitude_correlation_adjustment\n",
      "Took 3.5884 seconds on average for\n",
      "avg_train_loss: 1.4848 (0.65%)\n",
      "avg_val_loss: 1.5307 (1.86%)\n",
      "importance: 0.0000 (-100.00%)\n",
      "\n",
      "Removing influence with stochastic_fine_tuning\n",
      "Took 3.0420 seconds on average for\n",
      "avg_train_loss: 1.4976 (1.57%)\n",
      "avg_val_loss: 1.5239 (1.41%)\n",
      "importance: 0.0267 (-66.78%)\n",
      "\n",
      "Removing influence with inversion_fine_tuning\n",
      "Took 3.1158 seconds on average for\n",
      "avg_train_loss: 1.4831 (0.55%)\n",
      "avg_val_loss: 1.5057 (0.19%)\n",
      "importance: 0.0619 (-22.88%)\n",
      "\n",
      "Removing influence with simple_retraining\n",
      "Took 16.7170 seconds on average for\n",
      "avg_train_loss: 1.4968 (1.50%)\n",
      "avg_val_loss: 1.5216 (1.25%)\n",
      "importance: 0.0000 (-100.00%)\n",
      "\n",
      "\n",
      "RESULTS FOR REMOVING FEATURE 8 INFLUENCE:\n",
      "Removing influence with greedy_amplitude_correlation_adjustment\n",
      "Took 3.3773 seconds on average for\n",
      "avg_train_loss: 1.4839 (0.63%)\n",
      "avg_val_loss: 1.5306 (1.85%)\n",
      "importance: 0.0000 (-100.00%)\n",
      "\n",
      "Removing influence with stochastic_fine_tuning\n",
      "Took 3.0177 seconds on average for\n",
      "avg_train_loss: 1.4977 (1.52%)\n",
      "avg_val_loss: 1.5223 (1.30%)\n",
      "importance: 0.0266 (-66.80%)\n",
      "\n",
      "Removing influence with inversion_fine_tuning\n",
      "Took 3.0815 seconds on average for\n",
      "avg_train_loss: 1.4837 (0.61%)\n",
      "avg_val_loss: 1.5041 (0.09%)\n",
      "importance: 0.0651 (-18.94%)\n",
      "\n",
      "Removing influence with simple_retraining\n",
      "Took 16.6749 seconds on average for\n",
      "avg_train_loss: 1.4957 (1.41%)\n",
      "avg_val_loss: 1.5209 (1.21%)\n",
      "importance: 0.0000 (-100.00%)\n",
      "\n",
      "\n",
      "RESULTS FOR REMOVING FEATURE 9 INFLUENCE:\n",
      "Removing influence with greedy_amplitude_correlation_adjustment\n",
      "Took 3.4817 seconds on average for\n",
      "avg_train_loss: 1.4849 (0.70%)\n",
      "avg_val_loss: 1.5311 (1.88%)\n",
      "importance: 0.0000 (-100.00%)\n",
      "\n",
      "Removing influence with stochastic_fine_tuning\n",
      "Took 3.2288 seconds on average for\n",
      "avg_train_loss: 1.4975 (1.54%)\n",
      "avg_val_loss: 1.5222 (1.29%)\n",
      "importance: 0.0278 (-65.39%)\n",
      "\n",
      "Removing influence with inversion_fine_tuning\n",
      "Took 3.1503 seconds on average for\n",
      "avg_train_loss: 1.4829 (0.59%)\n",
      "avg_val_loss: 1.5036 (0.05%)\n",
      "importance: 0.0627 (-21.85%)\n",
      "\n",
      "Removing influence with simple_retraining\n",
      "Took 16.5667 seconds on average for\n",
      "avg_train_loss: 1.4950 (1.33%)\n",
      "avg_val_loss: 1.5202 (1.16%)\n",
      "importance: 0.0000 (-100.00%)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# now set a target node that we are going to try to minimize the effect of\n",
    "# we are going to run each of the functions RUN_TIMES times to get an average time score\n",
    "# method_function: the method that we are using to try to remove the influence. the arguments to the funciton are standardized\n",
    "# input_model: this is the model that we want to remove the influence from\n",
    "# layer: the layer that we want to be targeting with the influence depreciation\n",
    "# node_num: the number node in the layer that we want to be limiting the influence of\n",
    "# train_loader: this is the loader that we should be using to pull the training data\n",
    "# val_loader: this is the validation dataset loader that we are going to use to evaluate the model\n",
    "def remove_influence(method_function, input_model, layer, node_num, train_loader, val_loader, epochs=10, patience=2):\n",
    "\n",
    "\t# print the method that we ar eusing\n",
    "\tprint(f\"Removing influence with {method_function.__name__}\")\n",
    "\n",
    "\t# the amount of time that it took for each iteration\n",
    "\ttime_arr = []\n",
    "\n",
    "\tval_loss_arr = []\n",
    "\ttrain_loss_arr = []\n",
    "\n",
    "\t# keeping track of the importance of the input\n",
    "\tret_importance_arr = []\n",
    "\n",
    "\t# make a copy of the input model\n",
    "\tnew_input_model = copy.deepcopy(input_model)\n",
    "\n",
    "\t# measure the influence of the feature that we are trying to cancel on the model\n",
    "\ttarget_feature_initial_importance = compute_importance_GRAD(baseline_model, val_loader)[layer][node_num]\n",
    "\n",
    "\t# compute the metrics for the original model\n",
    "\tinput_model.eval()\n",
    "\torig_train_loss = 0.0\n",
    "\twith torch.no_grad():\n",
    "\t\tfor inputs, labels in train_loader:\n",
    "\t\t\toutputs = input_model(inputs)\n",
    "\t\t\tloss = loss_function(outputs, labels)\n",
    "\t\t\torig_train_loss += loss.item()\n",
    "\torig_train_loss = orig_train_loss / len(train_loader)\n",
    "\n",
    "\torig_val_loss = 0.0\n",
    "\twith torch.no_grad():\n",
    "\t\tfor inputs, labels in val_loader:\n",
    "\t\t\toutputs = input_model(inputs)\n",
    "\t\t\tloss = loss_function(outputs, labels)\n",
    "\t\t\torig_val_loss += loss.item()\n",
    "\torig_val_loss = orig_val_loss / len(val_loader)\n",
    "\n",
    "\t\n",
    "\t# how many times are we going to run the operation\n",
    "\tfor run_instance in range(RUN_TIMES):\n",
    "\n",
    "\t\t# get the timer going\n",
    "\t\tstart_time = time.time()\n",
    "\n",
    "\t\t# run the function\n",
    "\t\t# each of the functions shoudl return a dictionary with at least the accuracy of the model that came out of the method\n",
    "\t\tret_dict = method_function(input_model=new_input_model, layer=layer, node_num=node_num, train_loader=train_loader, val_loader=val_loader, epochs=epochs, patience=patience)\n",
    "\n",
    "\t\t# get the end time\n",
    "\t\tend_time = time.time()\n",
    "\n",
    "\t\t# add the val and train loss to the array\n",
    "\t\tval_loss_arr.append(ret_dict['best_val_loss'])\n",
    "\t\ttrain_loss_arr.append(ret_dict['train_loss'])\n",
    "\t\tret_importance_arr.append(ret_dict['node_importance'])\n",
    "\n",
    "\t\t# add the seconds that it took to the time array\n",
    "\t\ttime_arr.append(end_time - start_time)\n",
    "\n",
    "\t# get the average runtime\n",
    "\tavg_runtime\t= np.array(time_arr).mean()\n",
    "\tavg_train_loss = np.array(train_loss_arr).mean()\n",
    "\tavg_val_loss = np.array(val_loss_arr).mean()\n",
    "\tavg_importance = np.array(ret_importance_arr).mean()\n",
    "\n",
    "\t# print how long that took\n",
    "\tprint(f\"Took {(avg_runtime):.4f} seconds on average for\")\n",
    "\tprint(f\"avg_train_loss: {avg_train_loss:.4f} ({(100 * ((avg_train_loss - orig_train_loss) / orig_train_loss)):.2f}%)\")\n",
    "\tprint(f\"avg_val_loss: {avg_val_loss:.4f} ({(100 * ((avg_val_loss - orig_val_loss) / orig_val_loss)):.2f}%)\")\n",
    "\tprint(f\"importance: {(avg_importance):.4f} ({(100 * ((avg_importance - target_feature_initial_importance) / target_feature_initial_importance)):.2f}%)\")\n",
    "\tprint()\n",
    "\n",
    "\treturn avg_runtime\n",
    "\n",
    "\n",
    "# start with the easiest version -- simple retraining of the entire machine learning model\n",
    "# each of these functions is going to return a dictionary that has all of the important metrics about the machine learning model\n",
    "# since it doesn't make sense to remove a feature deeper in the machine learning model during simple retraining\n",
    "# since that concept will just be represented in other nodes, we only do this for input features as a baseline\n",
    "def simple_retraining(input_model=None, layer=None, node_num=None, train_loader=None, val_loader=None, epochs=10, patience=2, verbose=False):\n",
    "\n",
    "\t# check that the layer and the feature that we are changing the influence of are legitimate\n",
    " \t# the layer is zero-indexed\n",
    "\tif layer is None:\n",
    "\t\traise ValueError(\"Invalid layer passed to the function\")\n",
    "\n",
    "\tif node_num is None:\n",
    "\t\traise ValueError(\"Invalid node_num passed to the function\")\n",
    "\n",
    "\tif train_loader is None:\n",
    "\t\traise ValueError(\"Invalid train_loader passed to the function\")\n",
    "\n",
    "\tif val_loader is None:\n",
    "\t\traise ValueError(\"Invalid val_loader passed to the function\")\n",
    "\n",
    "\n",
    "\t# neural network for the insurance dataset\n",
    "\t# as a baseline for the model\n",
    "\tclass SimpleRetrainInsuranceNN(nn.Module):\n",
    "\n",
    "\t\t# initialize the insurance neural network item\n",
    "\t\tdef __init__(self):\n",
    "\t\t\tsuper(SimpleRetrainInsuranceNN, self).__init__()\n",
    "\t\t\tself.foward_1 = nn.Linear(t_input_shape - 1, 32)\n",
    "\t\t\tself.foward_2 = nn.Linear(32, 16)\n",
    "\t\t\tself.foward_3 = nn.Linear(16, NUM_CLASSES)   \n",
    "\n",
    "\t\t# go forward through the neural network\n",
    "\t\tdef forward(self, x):\n",
    "\t\t\tx = F.relu(self.foward_1(x))\n",
    "\t\t\tx = F.relu(self.foward_2(x))\n",
    "\t\t\tx = self.foward_3(x)\n",
    "\t\t\treturn x\n",
    "\t\t\n",
    "\t# initialize a new model \n",
    "\tnew_input_model = SimpleRetrainInsuranceNN()\n",
    "\n",
    "\tloss_function = nn.CrossEntropyLoss()\n",
    "\toptimizer = optim.Adam(new_input_model.parameters(), lr=0.001)\n",
    "\n",
    "\t# retrain the model blocking the one input\n",
    "\tbest_val_loss = float('inf')\n",
    "\tpatience_counter = 0\n",
    "\n",
    "\t# lists to store loss values for plotting\n",
    "\ttrain_losses = []\n",
    "\tval_losses = []\n",
    "\tepochs_list = []\n",
    "\n",
    "\tfor epoch in range(epochs):\n",
    "\t\tnew_input_model.train()\n",
    "\t\trunning_loss = 0.0\n",
    "\n",
    "\t\tfor inputs, labels in train_loader:\n",
    "\n",
    "\t\t\tinputs = torch.cat((inputs[:, :node_num], inputs[:, node_num+1:]), dim=1)\n",
    "\t\t\t\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\toutputs = new_input_model(inputs)\n",
    "\t\t\tloss = loss_function(outputs, labels)\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\trunning_loss += loss.item()\n",
    "\n",
    "\t\tnew_input_model.eval()\n",
    "\t\tval_loss = 0.0\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tfor inputs, labels in val_loader:\n",
    "\n",
    "\t\t\t\tinputs = torch.cat((inputs[:, :node_num], inputs[:, node_num+1:]), dim=1)\n",
    "\t\t\t\toutputs = new_input_model(inputs)\n",
    "\t\t\t\tloss = loss_function(outputs, labels)\n",
    "\t\t\t\tval_loss += loss.item()\n",
    "\n",
    "\t\tepoch_loss = running_loss / len(train_loader)\n",
    "\t\tepoch_val_loss = val_loss / len(val_loader)\n",
    "\t\t# print(f'Epoch {epoch+1}, Loss: {epoch_loss}, Val Loss: {epoch_val_loss}')\n",
    "\n",
    "\t\ttrain_losses.append(epoch_loss)\n",
    "\t\tval_losses.append(epoch_val_loss)\n",
    "\t\tepochs_list.append(epoch + 1)\n",
    "\n",
    "\t\t# check if the validation loss improved\n",
    "\t\tif epoch_val_loss < best_val_loss:\n",
    "\t\t\tbest_val_loss = epoch_val_loss\n",
    "\t\t\tpatience_counter = 0\n",
    "\t\t\n",
    "\t\telse:\n",
    "\t\t\tpatience_counter += 1\n",
    "\n",
    "\t\t# check for early stopping\n",
    "\t\tif patience_counter > patience and verbose:\n",
    "\t\t\tprint(\"Stopping early due to increasing validation loss.\")\n",
    "\t\t\tbreak\n",
    "\n",
    "\t\t# print the statistics from this epoch\n",
    "\t\tif verbose:\n",
    "\t\t\tprint(f'Epoch {epoch+1}, Loss: {epoch_loss}, Val Loss: {epoch_val_loss}')\n",
    "\n",
    "\t# return a dictionary with the final values that are important\n",
    "\treturn {\n",
    "\t\t'best_val_loss': best_val_loss,\n",
    "\t\t'train_loss': running_loss / len(train_loader),\n",
    "\t\t'val_loss': val_loss / len(val_loader),\n",
    "\t\t'node_importance': 0, # if the input is not there then it literally cannot have influence on the output\n",
    "\t}\n",
    "\n",
    "\n",
    "\n",
    "# now do stochastic fine-tuning to see what the impact on the influence of the input feature is\n",
    "def stochastic_fine_tuning(input_model=None, layer=None, node_num=None, train_loader=None, val_loader=None, epochs=10, patience=2, verbose=False):\n",
    "\n",
    "\t# check that the layer and the feature that we are changing the influence of are legitimate\n",
    " \t# the layer is zero-indexed\n",
    "\tif layer is None: \n",
    "\t\traise ValueError(\"Invalid layer passed to the function\")\n",
    "\t\n",
    "\tif input_model is None: \n",
    "\t\traise ValueError(\"Invalid input_model passed to the function\")\n",
    "\n",
    "\tif node_num is None:\n",
    "\t\traise ValueError(\"Invalid node_num passed to the function\")\n",
    "\n",
    "\tif train_loader is None:\n",
    "\t\traise ValueError(\"Invalid train_loader passed to the function\")\n",
    "\n",
    "\tif val_loader is None:\n",
    "\t\traise ValueError(\"Invalid val_loader passed to the function\")\n",
    "\n",
    "\n",
    "\tloss_function = nn.CrossEntropyLoss()\n",
    "\toptimizer = optim.Adam(input_model.parameters(), lr=0.001)\n",
    "\n",
    "\t# computing the mean of the feature that we are trying to limit the influence of across the entire dataset\n",
    "\ttotal_sum = 0\n",
    "\ttotal_count = 0\n",
    "\tinput_model.eval() \n",
    "\twith torch.no_grad():\n",
    "\t\tfor inputs, _ in train_loader:\n",
    "\t\t\ttotal_sum += inputs[:, node_num].sum()\n",
    "\t\t\ttotal_count += inputs[:, node_num].numel()\n",
    "\tglobal_mean = total_sum / total_count\n",
    "\n",
    "\t# retrain the model blocking the one input\n",
    "\tbest_val_loss = float('inf')\n",
    "\tpatience_counter = 0\n",
    "\n",
    "\t# lists to store loss values for plotting\n",
    "\ttrain_losses = []\n",
    "\tval_losses = []\n",
    "\tepochs_list = []\n",
    "\n",
    "\tfor epoch in range(epochs):\n",
    "\t\tinput_model.train()\n",
    "\t\trunning_loss = 0.0\n",
    "\n",
    "\t\tfor inputs, labels in train_loader:\n",
    "\n",
    "\t\t\t# replace the feature that we are removing with a random variable\n",
    "\t\t\tinputs[:, node_num] = torch.randn_like(inputs[:, node_num]) + global_mean\n",
    "\t\t\t\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\toutputs = input_model(inputs)\n",
    "\t\t\tloss = loss_function(outputs, labels)\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\trunning_loss += loss.item()\n",
    "\n",
    "\t\tinput_model.eval()\n",
    "\t\tval_loss = 0.0\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tfor inputs, labels in val_loader:\n",
    "\n",
    "\t\t\t\t# replace the feature that we are removing with a random variable\n",
    "\t\t\t\tinputs[:, node_num] = torch.randn_like(inputs[:, node_num]) + global_mean\n",
    "\n",
    "\t\t\t\toutputs = input_model(inputs)\n",
    "\t\t\t\tloss = loss_function(outputs, labels)\n",
    "\t\t\t\tval_loss += loss.item()\n",
    "\n",
    "\t\tepoch_loss = running_loss / len(train_loader)\n",
    "\t\tepoch_val_loss = val_loss / len(val_loader)\n",
    "\t\t# print(f'Epoch {epoch+1}, Loss: {epoch_loss}, Val Loss: {epoch_val_loss}')\n",
    "\n",
    "\t\ttrain_losses.append(epoch_loss)\n",
    "\t\tval_losses.append(epoch_val_loss)\n",
    "\t\tepochs_list.append(epoch + 1)\n",
    "\n",
    "\t\t# check if the validation loss improved\n",
    "\t\tif epoch_val_loss < best_val_loss:\n",
    "\t\t\tbest_val_loss = epoch_val_loss\n",
    "\t\t\tpatience_counter = 0\n",
    "\t\t\n",
    "\t\telse:\n",
    "\t\t\tpatience_counter += 1\n",
    "\n",
    "\t\t# check for early stopping\n",
    "\t\tif patience_counter > patience and verbose:\n",
    "\t\t\tprint(\"Stopping early due to increasing validation loss.\")\n",
    "\t\t\tbreak\n",
    "\n",
    "\t\t# print the statistics from this epoch\n",
    "\t\tif verbose:\n",
    "\t\t\tprint(f'Epoch {epoch+1}, Loss: {epoch_loss}, Val Loss: {epoch_val_loss}')\n",
    "\n",
    "\n",
    "\t# compute the importance of the feature that we are trying to limit the influence of\n",
    "\tnode_importance = compute_importance_GRAD(input_model, val_loader)[layer][node_num]\n",
    "\n",
    "\t# return a dictionary with the final values that are important\n",
    "\treturn {\n",
    "\t\t'best_val_loss': best_val_loss,\n",
    "\t\t'train_loss': running_loss / len(train_loader),\n",
    "\t\t'val_loss': val_loss / len(val_loader),\n",
    "\t\t'node_importance': node_importance,\n",
    "\t}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# now do inversion fine-tuning where we try to remove the information that is contained in \n",
    "# the variable from the model training\n",
    "def inversion_fine_tuning(input_model=None, layer=None, node_num=None, train_loader=None, val_loader=None, epochs=10, patience=2, verbose=False):\n",
    "\n",
    "\t# check that the layer and the feature that we are changing the influence of are legitimate\n",
    " \t# the layer is zero-indexed\n",
    "\tif layer is None: \n",
    "\t\traise ValueError(\"Invalid layer passed to the function\")\n",
    "\t\n",
    "\tif input_model is None: \n",
    "\t\traise ValueError(\"Invalid input_model passed to the function\")\n",
    "\n",
    "\tif node_num is None:\n",
    "\t\traise ValueError(\"Invalid node_num passed to the function\")\n",
    "\n",
    "\tif train_loader is None:\n",
    "\t\traise ValueError(\"Invalid train_loader passed to the function\")\n",
    "\n",
    "\tif val_loader is None:\n",
    "\t\traise ValueError(\"Invalid val_loader passed to the function\")\n",
    "\n",
    "\n",
    "\tloss_function = nn.CrossEntropyLoss()\n",
    "\toptimizer = optim.Adam(input_model.parameters(), lr=0.001)\n",
    "\n",
    "\t# computing the mean of the feature that we are trying to limit the influence of across the entire dataset\n",
    "\ttotal_sum = 0\n",
    "\ttotal_count = 0\n",
    "\tinput_model.eval() \n",
    "\twith torch.no_grad():\n",
    "\t\tfor inputs, _ in train_loader:\n",
    "\t\t\ttotal_sum += inputs[:, node_num].sum()\n",
    "\t\t\ttotal_count += inputs[:, node_num].numel()\n",
    "\tglobal_mean = total_sum / total_count\n",
    "\n",
    "\t# retrain the model blocking the one input\n",
    "\tbest_val_loss = float('inf')\n",
    "\tpatience_counter = 0\n",
    "\n",
    "\t# lists to store loss values for plotting\n",
    "\ttrain_losses = []\n",
    "\tval_losses = []\n",
    "\tepochs_list = []\n",
    "\n",
    "\t# go through some amount of epochs\n",
    "\tfor epoch in range(epochs):\n",
    "\t\tinput_model.train()\n",
    "\t\trunning_loss = 0.0\n",
    "\n",
    "\t\tfor inputs, labels in train_loader:\n",
    "\n",
    "\t\t\t# replace the feature that we are removing with the inversion across the mean\n",
    "\t\t\t# of the variable in a similar fashion to grover's\n",
    "\t\t\tinputs[:, node_num] = inputs[:, node_num].mean() - 2 * (inputs[:, node_num] - global_mean)\n",
    "\t\t\t\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\toutputs = input_model(inputs)\n",
    "\t\t\tloss = loss_function(outputs, labels)\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\trunning_loss += loss.item()\n",
    "\n",
    "\t\tinput_model.eval()\n",
    "\t\tval_loss = 0.0\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tfor inputs, labels in val_loader:\n",
    "\n",
    "\t\t\t\t# replace the feature that we are removing with the inversion across the mean\n",
    "\t\t\t\t# of the variable in a similar fashion to grover's\n",
    "\t\t\t\tinputs[:, node_num] = inputs[:, node_num].mean() - 2 * (inputs[:, node_num] - global_mean)\n",
    "\n",
    "\t\t\t\toutputs = input_model(inputs)\n",
    "\t\t\t\tloss = loss_function(outputs, labels)\n",
    "\t\t\t\tval_loss += loss.item()\n",
    "\n",
    "\t\tepoch_loss = running_loss / len(train_loader)\n",
    "\t\tepoch_val_loss = val_loss / len(val_loader)\n",
    "\t\t# print(f'Epoch {epoch+1}, Loss: {epoch_loss}, Val Loss: {epoch_val_loss}')\n",
    "\n",
    "\t\ttrain_losses.append(epoch_loss)\n",
    "\t\tval_losses.append(epoch_val_loss)\n",
    "\t\tepochs_list.append(epoch + 1)\n",
    "\n",
    "\t\t# check if the validation loss improved\n",
    "\t\tif epoch_val_loss < best_val_loss:\n",
    "\t\t\tbest_val_loss = epoch_val_loss\n",
    "\t\t\tpatience_counter = 0\n",
    "\t\t\n",
    "\t\telse:\n",
    "\t\t\tpatience_counter += 1\n",
    "\n",
    "\t\t# check for early stopping\n",
    "\t\tif patience_counter > patience and verbose:\n",
    "\t\t\tprint(\"Stopping early due to increasing validation loss.\")\n",
    "\t\t\tbreak\n",
    "\n",
    "\t\t# print the statistics from this epoch\n",
    "\t\tif verbose:\n",
    "\t\t\tprint(f'Epoch {epoch+1}, Loss: {epoch_loss}, Val Loss: {epoch_val_loss}')\n",
    "\n",
    "\n",
    "\t# compute the importance of the feature that we are trying to limit the influence of\n",
    "\tnode_importance = compute_importance_GRAD(input_model, val_loader)[layer][node_num]\n",
    "\n",
    "\t# return a dictionary with the final values that are important\n",
    "\treturn {\n",
    "\t\t'best_val_loss': best_val_loss,\n",
    "\t\t'train_loss': running_loss / len(train_loader),\n",
    "\t\t'val_loss': val_loss / len(val_loader),\n",
    "\t\t'node_importance': node_importance,\n",
    "\t}\n",
    "\n",
    "\n",
    "# greedy_amplitude_correlation_adjustment essentially measures the correlation between amplitudes in the layer \n",
    "# just before the layer that we are trying to remove a node's influence from. Essentially, if there is a ndoe that we\n",
    "# are trying to remove the influence of located in layer i, then change the weights for all of the input nodes to \n",
    "# layer i+1 to remove the influence while maintaining the fidelity of the outputs of the layer\n",
    "def greedy_amplitude_correlation_adjustment(input_model=None, layer=None, node_num=None, train_loader=None, val_loader=None, epochs=10, patience=2, verbose=False, max_correlation_elements=3):\n",
    "\n",
    "\t# check that the layer and the feature that we are changing the influence of are legitimate\n",
    " \t# the layer is zero-indexed\n",
    "\tif layer is None: \n",
    "\t\traise ValueError(\"Invalid layer passed to the function\")\n",
    "\t\n",
    "\tif input_model is None: \n",
    "\t\traise ValueError(\"Invalid input_model passed to the function\")\n",
    "\n",
    "\tif node_num is None:\n",
    "\t\traise ValueError(\"Invalid node_num passed to the function\")\n",
    "\n",
    "\tif train_loader is None:\n",
    "\t\traise ValueError(\"Invalid train_loader passed to the function\")\n",
    "\n",
    "\tif val_loader is None:\n",
    "\t\traise ValueError(\"Invalid val_loader passed to the function\")\n",
    "\n",
    "\t# define the loss and the optimizer that we want to use\n",
    "\tloss_function = nn.CrossEntropyLoss()\n",
    "\toptimizer = optim.Adam(input_model.parameters(), lr=0.001)\n",
    "\n",
    "\t# clear the information\n",
    "\tnode_importance_clear_total_run()\n",
    "\n",
    "\t# register hooks and go through the model to get the intermediate outptus\n",
    "\tnode_importance_register_hooks(input_model)\n",
    "\n",
    "\t# go through each of the training data pieces and get the correlations\n",
    "\twith torch.no_grad():\n",
    "\t\tfor inputs, labels in train_loader:\n",
    "\n",
    "\t\t\tnode_importance_start_new_pass_through_with_input(inputs)\n",
    "\n",
    "\t\t\t# get the output of the model\n",
    "\t\t\toutputs = input_model(inputs)\n",
    "\n",
    "\t\t\tnode_importance_save_and_clear_influence_network_current_pass_through()\n",
    "\n",
    "\t# get the layer outputs of the model\n",
    "\tmodel_layer_outputs = node_importance_retrieve_and_return_entire_network_outputs()\n",
    "\n",
    "\t# stack all of the arrays to get the correlation\n",
    "\tstacked_arr = None\n",
    "\n",
    "\t# stack all of the arrays\n",
    "\tfor batch_arr in [t_outs[layer] for t_outs in model_layer_outputs]:\n",
    "\t\tif stacked_arr is None:\n",
    "\t\t\tstacked_arr = batch_arr\n",
    "\t\telse:\n",
    "\t\t\tstacked_arr = torch.cat((stacked_arr, batch_arr), dim=0)\n",
    "\n",
    "\t# print(f\"stacked_arr shape: {stacked_arr.shape}\")\n",
    "\n",
    "\t# run a regresison between the banned feature and all of the other features\n",
    "\t# to get the optimal construction\n",
    "\tt_data = copy.deepcopy(stacked_arr)\n",
    "\n",
    "\t# create the data for a regression\n",
    "\ty = t_data[:, node_num]  \n",
    "\tX = np.delete(t_data, node_num, axis=1)\n",
    "\n",
    "\t# create the regression\n",
    "\tmodel = LinearRegression(fit_intercept=False)\n",
    "\tmodel.fit(X, y)\n",
    "\n",
    "\t# checking the residuals\n",
    "\tresid_pred = model.predict(X)\n",
    "\tmean_resids = mean_absolute_error(y, resid_pred)\n",
    "\n",
    "\n",
    "\t# print(f\"Residual Error: {mean_resids}\")\n",
    "\t# print(y)\n",
    "\t# print(resid_pred)\n",
    "\n",
    "\t# get the coefficients of the regression\n",
    "\treg_coef = np.array(model.coef_)\n",
    "\n",
    "\n",
    "\t# now for the layer that we are considering we are greedily going to change the weights\n",
    "\t# to roughly approximate the old weight\n",
    "\t# print(f\"Shape of layer: {input_model.foward_1.weight.data.shape}\")\n",
    "\t# print(f\"Reg Coeffs: {reg_coef}\")\n",
    "\n",
    "\texample_input, _ = next(iter(train_loader))\n",
    "\texample_input = example_input[0]\n",
    "\tnew_weights = copy.deepcopy(input_model.foward_1.weight.data)\n",
    "\n",
    "\t# for each of the columns add reg_weight[i] * orig_banned_weight[i] to approximate the offset\n",
    "\tfor row_idx in range(len(input_model.foward_1.weight.data)):\n",
    "\n",
    "\t\t# get the offset that is associated with the regression\n",
    "\t\toffset = 0\n",
    "\n",
    "\t\t# iterate through each of the rows now\n",
    "\t\tfor col_idx in range(len(input_model.foward_1.weight.data[node_num]) - 1):\n",
    "\n",
    "\t\t\t# # check which node we are offsetting\n",
    "\t\t\t# if col_idx == node_num:\n",
    "\t\t\t# \toffset += 1\n",
    "\t\t\t\n",
    "\t\t\t# # adjust the weight\n",
    "\t\t\t# # print(f\" {row_idx} | {col_idx + offset} : {(reg_coef[col_idx] * new_weights[node_num][col_idx + offset])}\")\n",
    "\t\t\t# new_weights[row_idx][col_idx + offset] = new_weights[row_idx][col_idx + offset] + (reg_coef[col_idx] * new_weights[node_num][col_idx + offset])\n",
    "   \n",
    "\t\t\tif col_idx != node_num:\n",
    "\t\t\t\tnew_weights[row_idx][col_idx] += reg_coef[col_idx - (1 if col_idx > node_num else 0)] * new_weights[row_idx][node_num]\n",
    "\n",
    "\t\t# set the other weights to zero for the original input\n",
    "\t\tnew_weights[row_idx][node_num] = 0\n",
    "\n",
    "\t# update the weights\n",
    "\tinput_model.foward_1.weight.data = new_weights\n",
    "\n",
    "\n",
    "\t# new_weights[:, node_num] = 0\n",
    "\n",
    "\t# print()\n",
    "\t# print(example_input)\n",
    "\t# print()\n",
    "\n",
    "\t# for row_idx in range(len(input_model.foward_1.weight.data)):\n",
    "\t# \tfor col_idx in range(len(input_model.foward_1.weight.data[node_num])):\n",
    "\t# \t\tprint(f\"{(input_model.foward_1.weight.data)[row_idx][col_idx]} | {(new_weights)[row_idx][col_idx]}\")\n",
    "\n",
    "\t# orig_output = example_input @ input_model.foward_1.weight.data.T\n",
    "\t# new_output = example_input @ input_model.foward_1.weight.data.T\n",
    "\n",
    "\t# print(orig_output)\n",
    "\t# print(new_output)\n",
    "\t# print(orig_output - new_output)\n",
    "\n",
    "\t# for row in (input_model.foward_1.weight.data):\n",
    "\t# \tprint(row)\n",
    "\n",
    "\t# print the reconstruction and correlation indexes\n",
    "\t# print(f'Attempting to reconstruct ')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\t# retrain the model blocking the one input\n",
    "\tbest_val_loss = float('inf')\n",
    "\tpatience_counter = 0\n",
    "\n",
    "\t# lists to store loss values for plotting\n",
    "\ttrain_losses = []\n",
    "\tval_losses = []\n",
    "\tepochs_list = []\n",
    "\n",
    "\t# run a few epochs while blocking the gradient for the bad input\n",
    "\tfor epoch in range(epochs):\n",
    "\t\t\n",
    "\t\tinput_model.train()\n",
    "\t\trunning_loss = 0.0\n",
    "\n",
    "\t\tfor inputs, labels in train_loader:\n",
    "\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\toutputs = input_model(inputs)\n",
    "\t\t\tloss = loss_function(outputs, labels)\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\trunning_loss += loss.item()\n",
    "\n",
    "\t\t# set some of the weights to zero\n",
    "\t\tinput_model.foward_1.weight.data[:, node_num] = 0\n",
    "\n",
    "\t\tinput_model.eval()\n",
    "\t\tval_loss = 0.0\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tfor inputs, labels in val_loader:\n",
    "\n",
    "\t\t\t\toutputs = input_model(inputs)\n",
    "\t\t\t\tloss = loss_function(outputs, labels)\n",
    "\t\t\t\tval_loss += loss.item()\n",
    "\n",
    "\t\tepoch_loss = running_loss / len(train_loader)\n",
    "\t\tepoch_val_loss = val_loss / len(val_loader)\n",
    "\t\t# print(f'Epoch {epoch+1}, Loss: {epoch_loss}, Val Loss: {epoch_val_loss}')\n",
    "\n",
    "\t\ttrain_losses.append(epoch_loss)\n",
    "\t\tval_losses.append(epoch_val_loss)\n",
    "\t\tepochs_list.append(epoch + 1)\n",
    "\n",
    "\t\t# check if the validation loss improved\n",
    "\t\tif epoch_val_loss < best_val_loss:\n",
    "\t\t\tbest_val_loss = epoch_val_loss\n",
    "\t\t\tpatience_counter = 0\n",
    "\t\t\n",
    "\t\telse:\n",
    "\t\t\tpatience_counter += 1\n",
    "\n",
    "\t\t# check for early stopping\n",
    "\t\tif patience_counter > patience and verbose:\n",
    "\t\t\tprint(\"Stopping early due to increasing validation loss.\")\n",
    "\t\t\tbreak\n",
    "\n",
    "\t\t# print the statistics from this epoch\n",
    "\t\tif verbose:\n",
    "\t\t\tprint(f'Epoch {epoch+1}, Loss: {epoch_loss}, Val Loss: {epoch_val_loss}')\n",
    "\n",
    "\n",
    "\t# placing the model in evaluation mode\n",
    "\tinput_model.eval()\n",
    "\tval_loss = 0.0\n",
    "\twith torch.no_grad():\n",
    "\t\tfor inputs, labels in val_loader:\n",
    "\n",
    "\t\t\toutputs = input_model(inputs)\n",
    "\t\t\tloss = loss_function(outputs, labels)\n",
    "\t\t\tval_loss += loss.item()\n",
    "\n",
    "\n",
    "\t# compute the importance of the feature that we are trying to limit the influence of\n",
    "\tnode_importance = compute_importance_GRAD(input_model, val_loader)\n",
    "\ttarget_importance = node_importance[layer][node_num]\n",
    "\n",
    "\n",
    "\t# return a dictionary with the final values that are important\n",
    "\treturn {\n",
    "\t\t'best_val_loss': best_val_loss,\n",
    "\t\t'train_loss': running_loss / len(train_loader),\n",
    "\t\t'val_loss': val_loss / len(val_loader),\n",
    "\t\t'node_importance': target_importance,\n",
    "\t}\n",
    "\n",
    "\t\n",
    "# define the loss function and optimizer that we are going to be using to train the neural network\n",
    "\n",
    "# for feat_num in [0, 5, 7, 9]:\n",
    "for feat_num in range(10):\n",
    "\n",
    "\tprint(f\"RESULTS FOR REMOVING FEATURE {feat_num} INFLUENCE:\")\n",
    "\n",
    "\t# try each of the methods\n",
    "\tavg_inversion_retrain_time = remove_influence(greedy_amplitude_correlation_adjustment, baseline_model, layer=LAYER_NUM, node_num=FEATURE_NUM, train_loader=train_loader, val_loader=val_loader, epochs=5)\n",
    "\n",
    "\tavg_stochastic_retrain_time = remove_influence(stochastic_fine_tuning, baseline_model, layer=LAYER_NUM, node_num=FEATURE_NUM, train_loader=train_loader, val_loader=val_loader, epochs=5)\n",
    "\tavg_inversion_retrain_time = remove_influence(inversion_fine_tuning, baseline_model, layer=LAYER_NUM, node_num=FEATURE_NUM, train_loader=train_loader, val_loader=val_loader, epochs=5)\n",
    "\tavg_simple_retrain_time = remove_influence(simple_retraining, baseline_model, layer=LAYER_NUM, node_num=FEATURE_NUM, train_loader=train_loader, val_loader=val_loader, epochs=30)\n",
    "\n",
    "\tprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old Code:\n",
    "\n",
    "This was the original dynamic programming approach that was used to find the optimal weighting of the original inputs. I found that the linear regression approach detailed above is more effective. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a sub-function that uses a dynamic programming approach to find the set of elements that\n",
    "# when summed has a correlation closest to the original input\n",
    "# corr_arr: has the correlation values of all of the other elements in the array\n",
    "# max_correlation_elements: the maximum number of elements that we are allowed to use to reconstruct the correlation\n",
    "# orig_weight_ind: the index of the original banned feature (do not use)\n",
    "def find_closest_sum_dp(corr_arr, max_correlation_elements, orig_weight_ind):\n",
    "\n",
    "\t# define a base case\n",
    "\tclosest = {}\n",
    "\tclosest[(0, 0)] = (0, [])\n",
    "\n",
    "\t# check each correlation value in the correlation array\n",
    "\tfor idx, corr_val in enumerate(corr_arr):\n",
    "\n",
    "\t\t# do not consider the index that contains the original weight\n",
    "\t\tif idx == orig_weight_ind:\n",
    "\t\t\tcontinue\n",
    "\t\t\n",
    "\t\t# keep track of the current sums\n",
    "\t\tupdates = []\n",
    "\n",
    "\t\t# check the rest of the sums\n",
    "\t\tfor (count, sum_so_far), (current_closest, indices) in closest.items():\n",
    "\n",
    "\t\t\t# make sure that we don't add too many elements\n",
    "\t\t\tif count + 1 > max_correlation_elements: \n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t# check the new summation value\n",
    "\t\t\tnew_sum = sum_so_far + corr_val\n",
    "\t\t\tnew_indices = indices.append(idx)\n",
    "\n",
    "\t\t\t# create the key that we can use to index\n",
    "\t\t\tnew_key = (count + 1, new_sum)\n",
    "\t\t\t\n",
    "\t\t\t# check if this is better than before\n",
    "\t\t\tif new_key not in closest or abs(1 - new_sum) < abs(1 - closest[new_key]):\n",
    "\t\t\t\tupdates.append((new_key, (new_sum, new_indices)))\n",
    "\n",
    "\t\t# update the dictionary\n",
    "\t\tfor key, value in updates:\n",
    "\t\t\tclosest[key] = value\n",
    "\n",
    "\t# find the closest sum to 1 from all entries considering up to m elements\n",
    "\tclosest_to_one = None\n",
    "\tmin_difference = float('inf')\n",
    "\tbest_indices = []\n",
    "\t\n",
    "\t# find the element that adheres to the maximum values condition\n",
    "\tfor (count, sum_so_far), (sum_value, t_ind) in closest.items():\n",
    "\n",
    "\t\t# return and update the best value\n",
    "\t\tif count <= max_correlation_elements and abs(1 - sum_value) < min_difference:\n",
    "\t\t\tmin_difference = abs(1 - sum_value)\n",
    "\t\t\tclosest_to_one = sum_value\n",
    "\t\t\tbest_indices = t_ind\n",
    "\n",
    "\t# return the best combination\n",
    "\treturn (closest_to_one, best_indices)\n",
    "\n",
    "\n",
    "# # for the feature that we are trying to limit the influence of get the correlation\n",
    "# banned_feature_corr = correlation_matrices[layer][node_num]\n",
    "\n",
    "# # get the best correlations\n",
    "# (reconstructed_correlation, reconstruction_indexes) = find_closest_sum_dp(banned_feature_corr, max_correlation_elements, node_num)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
